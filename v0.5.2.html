<!doctype html>
<html lang="en">
<meta charset="utf-8">
<link rel="stylesheet" href="style-v0.5.2.css">
<title>
klay's cookbook for web server admins
</title>
<h1>klay's cookbook for web server admins, v0.5.2</h1>

<nav>
<a href="/">home</a>
| <a href=".">latest</a>
</nav>

<section>
<h2>audience</h2>
who is this guide for? me, of course. I'm finding out what I like and writing it down so I can repeat it. and if other people like what I like, then they can use this guide too.
<p>
there's an old <a href="https://www.reddit.com/r/geek/comments/4zl3e1/happy_birthday_linux_heres_your_cake/">joke</a> that using Linux is like ordering a cake and receiving a bunch of flour, sugar, butter, and eggs. a guide is too general if it goes on at length about folding wheat proteins to form gluten. a guide is too specific if it requires a box of pre-made cake mix. what I want is a guide that tells me how to make a specific cake, but also tells me what each ingredient does and when I can substitute it. I want a cookbook.
<p>
if you're like me, you already find code inherently fun and beautiful. you know about <a href="https://esolangs.org/">esolangs</a> and <a href="https://conlang.org/">conlangs</a>. you've read <a href="https://archive.org/details/godelescherbachaneternalgoldenbraiddouglasr.hofstadter"><em>Godel, Escher, Bach</em></a> or at least <a href="https://xkcd.com/">xkcd</a>. you're old enough to have used <a href="https://en.wikipedia.org/wiki/Internet_Relay_Chat">IRC</a> or young enough to have played <a href="https://minecraft.fandom.com/wiki/Tutorials/Setting_up_a_server">Minecraft</a>. you understand that 'the cloud' is just other peoples' computers.
<p>
and you want one of them to be yours.
</section>

<section>
<h2>materials</h2>
I'll be using a <a href="https://www.raspberrypi.com/">Raspberry Pi 4b</a> and installing <a href="https://www.armbian.com/">armbian v23.5.1</a>. if the Raspberry Pi isn't available where and when you are, a good alternative is the <a href="https://www.pine64.org/devices/single-board-computers/rock64/">ROCK64</a>. you'll also need a MicroSD card, I recommend 64GB, and a hard drive, I recommend 2TB, plus a second hard drive for backup. the pi can just about power one hard drive on its own, but if you want to plug both in at once you'll need a powered hard drive enclosure or a powered usb hub.
<p>
you can adapt these directions to any machine that can run <a href="https://www.debian.org/doc/">Debian</a>, like an old laptop or desktop pc. you can also rent a virtual machine running in a remote datacenter. the cheapest virtual machine on <a href="https://www.digitalocean.com/">DigitalOcean</a> is only $6/mo as of this writing, and comes with 25GB of storage. renting a machine in a datacenter means you get the perks of high-speed internet all day and night, great if you're running a game server and need a fast connection. however, you'll pay about $10/mo for every additional 100GB of storage, so it's not great if you want to host a huge media archive.
</section>

<section>
<h2>operating system</h2>
first, download and install the operating system. there are lots of guides on how to install Linux already, <a href="https://docs.armbian.com/User-Guide_Getting-Started/">here's</a> one for armbian. you may need to plug in an external keyboard and monitor for this step. we can unplug those later, giving us a CLI or "headless" server. 
<p>
the installation should walk you through creating a new username and password, I recommend <a href="https://xkpasswd.net/s/">a long random phrase</a>. write it down. you can't hack a piece of paper.
<p>
log in as 'root', the built-in administrator account. if your install guide doesn't provide a root login, then use this command to borrow one.
<pre>
$ sudo su
</pre>
throughout this guide, I'll be using <code>$</code> at the start of a command if you run it as a normal user, or <code>#</code> if you run it while logged in as root. either way, you don't actually type this symbol yourself, it should already appear on your command line.
<p>
once you're logged in as root, do some system updates. 'apt' is the package manager built into Debian, it holds all your system software and lots of fun optional stuff too.
<pre>
# apt update
# apt upgrade
</pre>
next, set your hostname. this is how you will appear to other computers on the network. for this example I'll use 'teapot'.
<pre>
# hostnamectl set-hostname teapot
</pre>
I'd like to be able to connect to this machine using its hostname. there's a tool for this called 'avahi-daemon'.
<pre>
# apt install avahi-daemon
</pre>
this is a good time to reboot, to make sure the updated hostname is in use:
<pre>
# reboot
</pre>
you should now be able to log into the server from another machine, with
<pre>
$ ssh yourname@teapot
</pre>
or
<pre>
$ ssh yourname@teapot.local
</pre>
</section>

<section>
<h2>format storage</h2>
the Raspberry Pi and the ROCK64 both use a MicroSD card as the operating system disk. it's clever; if the os breaks you can just pull its brain out, factory reset it, and pop it back in. however, I don't want to store all my user data on that brain card. I think it's better if you have a secondary disk that contains <em>only</em> the stuff you create yourself. that way if something goes wrong and you have to reset the brain card, you don't lose any of your pictures or music or whatever.
<p>
there are different formats for a data disk. the format determines exactly where the data and metadata will appear in each 'chunk' on the disk. windows typically uses <a href="https://en.wikipedia.org/wiki/NTFS">NTFS</a>, which supports metadata for ownership and modified time, but not for fine-grained access like whether guests are allowed to open the file in read-only mode. Linux uses a format that does allow this fine-grained access, called <a href="https://en.wikipedia.org/wiki/Ext4">ext4</a>, so that's what we need to format our data disk as.
<p>
<strong>‚ö†Ô∏è warning! this will erase everything on the disk!</strong>
<p>
first we need to identify the disk's device file. in Linux, everything you can read or write to is treated as a file, including a usb device like an external disk. note that this device file is not the same as a filesystem mount. we'll cover mounting later.
<p>
unplug the disk. run the command <code>fd</code>. plug the disk back in. run <code>fd</code> again, and compare its output to before. there should be exactly one new entry, and it should look like <code>/dev/sda</code> or <code>/dev/sdb2</code>. if you're not sure which disk it is, don't risk it, phone a friend. 
<p>
format the disk:
<pre>
$ sudo mkfs.ext4 /dev/sda
</pre>
and label it:
<pre>
$ sudo e2label /dev/sda teapot-data
</pre>
</section>

<section>
<h2>mount storage</h2>
Linux doesn't use drive letters like Windows does. Instead, every disk's filesystem lives at some <em>path</em>. the main, or "root" path is <code>/</code>, a single slash, and usually belongs to the main disk, in this case the MicroSD card. we'll create a new path at <code>/data</code> for our data disk.
<p>
<pre>
$ sudo mkdir /data
</pre>
when the system boots up, it looks in the system file <code>/etc/fstab</code> to find out what disks live at what paths. since we gave our disk a label earlier, we can mount it using that label. 
<p>
edit fstab:
<pre>
$ sudo nano /etc/fstab
</pre>
add this line:
<pre>
LABEL=teapot-data /data ext4 nofail,x-systemd.device-timeout=5s,x-systemd.automount 0 0
</pre>
there's a lot going on here. you can <a href="https://www.freedesktop.org/software/systemd/man/systemd.mount.html#fstab">read more</a> about how fstab and systemd work together, but basically what we're saying is:
<ul>
    <li>find the disk labeled "teapot-data" and mount it at /data, as an ext4 filesystem.</li>
    <li>nofail: if the disk is missing at boot time, skip it and finish booting anyway.</li>
    <li>x-systemd.device-timeout=5s: wait 5 seconds before giving up.</li>
    <li>x-systemd.automount: if someone tries to access the disk and it's not mounted, try mounting it again.</li>
</ul>
we're using a delayed mounting process here because we want to make sure our server still comes online, even if the disk fails to load. if the server crashed on boot we'd have to go physically plug in a keyboard and monitor to fix it. with nofail, we can still log in remotely.
<p>
save and exit the file if you haven't already, then check it:
<pre>
$ sudo mount --all --fake --verbose
</pre>
<ul>
    <li>--all: apply all the rules from <code>/etc/fstab</code>.</li>
    <li>--fake: don't <em>actually</em> apply the rules, just check that they're written correctly.</li>
    <li>--verbose: give detailed feedback. Linux programs typically say nothing unless there is an error.</li>
</ul>
if all your mounts pass inspection, now is a good time to reboot the machine.
<pre>
$ sudo reboot now
</pre>
</section>

<section>
<h2>backups</h2>
I'll write a longer section about backups later, but basically: buy a second disk, and every month or so, copy the entirety of the first disk to the second one. it's a quick and dirty solution and it's better than having no backups at all. the command you want is
<pre>
rsync -axHAWXS --numeric-ids --info=progress2 &lt;source&gt; &lt;dest&gt;
</pre>
explanation <a href="https://superuser.com/a/1185401">here</a>.
<p>
</section>

<section>
<h2>apps</h2>
at this point, we'll take a detour and talk about containers. everything we've done so far has involved making changes to system files. if you need to copy your data to a new system you'll have to change all those system files again, and this gets more complicated the more things are installed. thankfully, most useful applications can now be installed as <strong>containers</strong>, which <em>contain</em> all their own data and system files. think of the host machine as a <a href="https://www.ikea.com/us/en/cat/kallax-shelving-units-58285/">shelf</a>, and each container as a cubby on that shelf. this added structure keeps apps from touching each other's files, and makes it easier to remove things later.
<p>
we'll be using <a href="https://podman.io/">Podman</a>, a container host service that allows you to work with either individual containers, or with groups of containers called <strong>pods</strong>. in our shelf analogy, a pod is a cubby which has been sub-divided into <a href="https://www.ikea.com/us/en/cat/inserts-accessories-for-kallax-58286/">more cubbies</a>, but still takes up a single space on the original shelf.
<p>
podman has a few optional packages that I recommend, we'll install them all now:
<pre>
$ sudo apt install podman uidmap slirp4netns python3-pip
$ sudo pip install podman-compose==1.0.3
</pre>
<ul>
    <li>uidmap: needed to make fake users inside a container, necessary when running a container <strong>rootless</strong>, without sudo.</li>
    <li>slirp4netns: used to make private networks between containers.</li>
    <li>python3-pip: an alternative package manager specifically for <a href="https://www.python.org/">Python</a> programs, we need this to install <a href="https://github.com/containers/podman-compose#podman-compose">podman-compose</a>.</li>
    <li>podman-compose: a very handy tool that lets you store your container instructions in a script file to use later, we'll cover this soon!</li>
</ul>
<strong>üí° I had compatibility issues with podman-compose v1.0.6 during this writing. use v1.0.3 for now.</strong>
<p>
let's test it out by running <a href="https://nginx.org/">nginx</a> (pronounced 'engine-x'), a simple and fast web server. we'll use the image published by <a href="https://hub.docker.com/">Docker Hub</a>. think of an <strong>image</strong> as a photo negative or a resin mold: you can't run an image directly, but you can use it to produce a filled container.
<pre>
$ podman run --rm -p 9000:80 docker.io/library/nginx
</pre>
<ul>
    <li>podman run: create a new container and start it immediately.</li>
    <li>--rm: remove the container automatically when the main program exits.</li>
    <li>-p 9000:80: connect port 9000 on the host to port 80 inside the container. ports are like the networking equivalent of a post office box or a room number, they allow you to send messages to a specific program inside a machine. web browsers send messages to port 80 by default, so that's what nginx is listening for, but we need permission to bind to ports less than 1024, since they're older and have special meanings. without that permission, we can use any port between 1024 and 65535. 9000 is an arbitrary, easy-to-remember choice.</li>
    <li>docker.io/library/nginx: the name of the image we're building. this has to come last, because anything that comes after the image name is instructions for the program inside the container, not for podman. in this case we're not giving any instructions after the image name though, because we want to run the default command for this image.</li>
</ul>
if you get an error like "delete libpod local files to resolve", then you may need to do this extra step, then try again:
<pre>
$ sudo rm ~/.local/share/containers
</pre>
otherwise, you should now be able to point a web browser at <a href="http://teapot.local:9000">http://teapot.local:9000</a> and you will see the nginx test page!
<p>
finally, we'll use podman-compose to save our setup. create a folder in <code>/data</code> for this container, and make a new file called <code>compose.yaml</code>.
<pre>
$ sudo mkdir /data/nginx
$ cd /data/nginx
$ sudo nano compose.yaml
</pre>
contents of <code>compose.yaml</code>:
<pre>
version: '3'
services:
  nginx:
    image: docker.io/library/nginx
    ports:
      - 9000:80
</pre>
this does the same thing as our command from before. it starts one service container, running nginx, with port 9000 on the host mapped to port 80 in the container. to run this script, type
<pre>
$ sudo podman-compose up -d
</pre>
and to stop it again:
<pre>
$ sudo podman-compose down
</pre>
</section>

<!-- 
todo
- serve a static website with nginx
- configure nginx to serve php content too
- set up a database?
- host a dockerized app with nginx proxy-pass 
- firewall safety
- hosting from your home router (with hairpin/reflection NAT)
-->
